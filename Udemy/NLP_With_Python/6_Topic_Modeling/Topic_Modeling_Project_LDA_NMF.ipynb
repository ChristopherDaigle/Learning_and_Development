{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Using LDA and NMF\n",
    "**Data:** Quora.com questions without labels, >400,000 observations\n",
    "> Suggested 20 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('quora_questions.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing\n",
    "* Clean data, create TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Question    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 empty rows from the data; now contains 404289 rows\n"
     ]
    }
   ],
   "source": [
    "raw_leng = len(df)\n",
    "display(df.isnull().sum())\n",
    "df.dropna(inplace=True)\n",
    "display(df.isnull().sum())\n",
    "\n",
    "blanks = []\n",
    "for i,q in df.itertuples():\n",
    "    if type(q) == str:\n",
    "        if q.isspace():\n",
    "            blanks.append(i)\n",
    "df.drop(blanks,inplace=True)\n",
    "\n",
    "clean_leng = len(df)\n",
    "\n",
    "print(\"Removed {} empty rows from the data; now contains {} rows\".format(raw_leng - clean_leng, clean_leng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_df=0.9,min_df=10,stop_words='english')\n",
    "tfidf = TfidfVectorizer(max_df=0.9,min_df=10,stop_words='english')\n",
    "\n",
    "dtm_cv = cv.fit_transform(df['Question'])\n",
    "dtm_tf = tfidf.fit_transform(df['Question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Non-Negative Matrix Factorization\n",
    "* import, define, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=20, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "nmf_model = NMF(n_components=20, random_state=42)\n",
    "nmf_model.fit(dtm_tf)\n",
    "\n",
    "LDA_model = LatentDirichletAllocation(n_components=20, random_state=42)\n",
    "LDA_model.fit(dtm_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate common terms in each suggested topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 words for topic # 0\n",
      "['best', 'movies', 'book', 'books', '2016', 'ways', 'movie', 'laptop', 'buy', 'phone', 'places', 'visit', 'place', 'read', 'site']\n",
      "\n",
      "Top 15 words for topic # 1\n",
      "['does', 'mean', 'work', 'feel', 'long', 'cost', 'compare', 'really', 'exist', 'use', 'differ', 'looking', 'recruit', 'sex', 'grads']\n",
      "\n",
      "Top 15 words for topic # 2\n",
      "['quora', 'questions', 'question', 'ask', 'answer', 'answers', 'google', 'asked', 'delete', 'improvement', 'easily', 'post', 'needing', 'answered', 'add']\n",
      "\n",
      "Top 15 words for topic # 3\n",
      "['money', 'make', 'online', 'earn', 'ways', 'youtube', 'easy', 'home', 'com', 'free', 'internet', 'black', 'friends', 'website', 'using']\n",
      "\n",
      "Top 15 words for topic # 4\n",
      "['life', 'purpose', 'meaning', 'thing', 'important', 'real', 'moment', 'live', 'want', 'change', 'changed', 'death', 'day', 'earth', 'work']\n",
      "\n",
      "Top 15 words for topic # 5\n",
      "['india', 'pakistan', 'war', 'spotify', 'job', 'available', 'country', 'olympics', 'china', 'engineering', 'minister', 'company', 'reservation', 'president', 'business']\n",
      "\n",
      "Top 15 words for topic # 6\n",
      "['people', 'think', 'don', 'ask', 'hate', 'believe', 'questions', 'use', 'flat', 'google', 'mind', 'easily', 'stop', 'blowing', 'chinese']\n",
      "\n",
      "Top 15 words for topic # 7\n",
      "['learn', 'language', 'programming', 'start', 'learning', 'java', 'languages', 'python', 'want', 'book', 'online', 'hacking', 'computer', 'beginners', 'beginner']\n",
      "\n",
      "Top 15 words for topic # 8\n",
      "['like', 'feel', 'look', 'sex', 'work', 'girl', 'live', 'girls', 'culture', 'women', 'men', 'companies', 'don', 'guy', 'different']\n",
      "\n",
      "Top 15 words for topic # 9\n",
      "['trump', 'donald', 'clinton', 'president', 'hillary', 'win', 'election', 'better', 'vote', 'think', '2016', 'presidential', 'presidency', 'happen', 'america']\n",
      "\n",
      "Top 15 words for topic # 10\n",
      "['difference', 'engineering', 'computer', 'science', 'software', 'data', 'java', 'scripting', 'chinese', 'better', 'programming', 'learning', 'web', 'main', 'company']\n",
      "\n",
      "Top 15 words for topic # 11\n",
      "['good', 'books', 'bad', 'ways', 'engineering', 'work', 'job', 'provider', 'panel', 'solar', 'installation', 'ca', 'california', 'business', 'songs']\n",
      "\n",
      "Top 15 words for topic # 12\n",
      "['know', 'new', 'things', 'day', 'going', 'employees', 'don', 'year', '2017', 'girl', 'likes', 'mind', 'resolution', 'resolutions', 'blowing']\n",
      "\n",
      "Top 15 words for topic # 13\n",
      "['500', 'notes', '1000', 'rs', 'rupee', 'indian', 'black', 'banning', 'ban', 'think', 'government', 'economy', 'currency', 'modi', 'money']\n",
      "\n",
      "Top 15 words for topic # 14\n",
      "['english', 'improve', 'skills', 'writing', 'speaking', 'pronunciation', 'speak', 'communication', 'fluently', 'language', 'ways', 'spoken', 'word', 'skill', 'fluent']\n",
      "\n",
      "Top 15 words for topic # 15\n",
      "['weight', 'lose', 'gain', 'ways', 'fat', 'fast', 'loss', 'quickly', 'reduce', 'month', 'pounds', 'exercise', 'help', 'healthy', 'diet']\n",
      "\n",
      "Top 15 words for topic # 16\n",
      "['time', 'travel', 'possible', 'sex', 'home', 'job', 'movies', 'favorite', 'machine', 'person', 'long', 'spend', 'feel', 'real', 'having']\n",
      "\n",
      "Top 15 words for topic # 17\n",
      "['love', 'fall', 'girl', 'person', 'know', 'true', 'really', 'friend', 'tell', 'forget', 'feel', 'girlfriend', 'sex', 'marriage', 'parents']\n",
      "\n",
      "Top 15 words for topic # 18\n",
      "['way', 'easiest', 'suicide', 'fastest', 'commit', 'best', 'account', 'instagram', 'painless', 'increase', 'facebook', 'start', 'prepare', 'quickest', 'rid']\n",
      "\n",
      "Top 15 words for topic # 19\n",
      "['did', 'world', 'war', 'start', 'win', 'thing', 'business', 'country', 'happen', 'iii', 'end', 'battle', 'die', 'change', 'pakistan']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(nmf_model.components_):\n",
    "    print(f'Top 15 words for topic # {i}')\n",
    "    print([tfidf.get_feature_names()[i] for i in t.argsort()[-15:]][::-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 words for topic # 0\n",
      "['does', 'know', 'start', 'feel', 'really', 'like', 'don', 'want', 'rid', 'mind', 'exist', 'friends', 'people', 'need', 'build']\n",
      "\n",
      "Top 15 words for topic # 1\n",
      "['new', 'does', 'computer', 'science', 'interesting', 'worth', 'music', 'looking', 'year', '2017', 'biggest', 'house', 'city', 'facts', 'apple']\n",
      "\n",
      "Top 15 words for topic # 2\n",
      "['love', 'girl', 'read', 'books', 'guy', 'favorite', 'friend', 'tell', 'girlfriend', 'best', 'class', 'know', 'time', 'history', 'man']\n",
      "\n",
      "Top 15 words for topic # 3\n",
      "['improve', 'country', 'change', 'car', 'password', 'english', 'email', 'skills', 'effects', 'gmail', 'writing', 'air', 'countries', 'does', 'legal']\n",
      "\n",
      "Top 15 words for topic # 4\n",
      "['did', 'world', 'day', 'things', 'war', 'going', 'happen', 'places', 'visit', 'know', 'pakistan', 'happened', 'employees', 'new', 'end']\n",
      "\n",
      "Top 15 words for topic # 5\n",
      "['does', 'way', 'best', 'mean', 'learn', 'long', 'sex', 'lose', 'work', 'ways', 'safe', 'weight', 'police', 'hotel', 'relationship']\n",
      "\n",
      "Top 15 words for topic # 6\n",
      "['use', 'used', 'word', 'card', 'hair', 'data', 'does', 'examples', 'big', 'states', 'united', 'service', 'kind', 'ca', 'sentence']\n",
      "\n",
      "Top 15 words for topic # 7\n",
      "['trump', 'donald', 'president', 'clinton', 'hillary', 'win', '2016', 'game', 'election', 'college', 'presidential', 'did', 'vote', 'alcohol', 'school']\n",
      "\n",
      "Top 15 words for topic # 8\n",
      "['difference', 'movie', 'human', 'god', 'did', 'believe', 'humans', 'live', 'does', '2016', 'startup', 'group', 'sydney', 'small', 'current']\n",
      "\n",
      "Top 15 words for topic # 9\n",
      "['best', 'phone', 'number', 'programming', 'language', 'android', 'app', 'iphone', 'mobile', 'learn', 'using', 'use', 'whatsapp', 'support', 'windows']\n",
      "\n",
      "Top 15 words for topic # 10\n",
      "['people', 'life', 'quora', 'real', 'ask', 'questions', 'think', 'right', 'answers', 've', 'purpose', 'seen', 'review', 'death', 'easily']\n",
      "\n",
      "Top 15 words for topic # 11\n",
      "['like', 'business', 'different', 'women', 'men', 'math', 'social', 'girls', 'indian', 'differences', 'culture', 'companies', 'chinese', 'media', 'idea']\n",
      "\n",
      "Top 15 words for topic # 12\n",
      "['quora', 'question', 'questions', 'job', 'average', 'interview', 'does', 'answer', 'process', 'meaning', 'tips', 'making', 'asked', 'compare', 'ones']\n",
      "\n",
      "Top 15 words for topic # 13\n",
      "['account', 'facebook', 'instagram', 'google', 'website', 'create', 'light', 'video', 'period', 'speed', 'games', 'food', 'pregnant', 'delete', 'days']\n",
      "\n",
      "Top 15 words for topic # 14\n",
      "['best', 'engineering', 'good', 'movies', 'study', 'company', 'com', 'book', 'india', 'university', 'job', 'student', 'software', 'career', 'write']\n",
      "\n",
      "Top 15 words for topic # 15\n",
      "['make', 'time', 'money', 'online', 'thing', 'english', 'earn', 'important', 'learning', 'travel', 'youtube', 'web', 'home', 'possible', 'learn']\n",
      "\n",
      "Top 15 words for topic # 16\n",
      "['good', 'old', 'stop', 'year', 'years', 'bad', 'people', 'does', 'age', 'increase', 'height', 'think', 'hate', 'work', 'differ']\n",
      "\n",
      "Top 15 words for topic # 17\n",
      "['does', 'water', 'weight', 'state', 'body', 'earth', 'self', 'test', 'gain', 'wrong', 'lose', 'terms', 'tax', 'actually', 'doing']\n",
      "\n",
      "Top 15 words for topic # 18\n",
      "['india', 'buy', 'best', 'energy', 'china', 'laptop', 'universe', 'law', 'created', 'dark', 'school', 'security', 'available', 'fat', 'british']\n",
      "\n",
      "Top 15 words for topic # 19\n",
      "['indian', '500', 'notes', '1000', 'black', 'rs', 'government', 'exam', 'money', 'rupee', 'india', 'modi', 'great', 'prepare', 'economy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(LDA_model.components_):\n",
    "    print(f'Top 15 words for topic # {i}')\n",
    "    print([tfidf.get_feature_names()[i] for i in t.argsort()[-15:]][::-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicate topic in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>NMF_Topic</th>\n",
       "      <th>LDA_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  NMF_Topic  LDA_Topic\n",
       "0  What is the step by step guide to invest in sh...          5          2\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...         17         19\n",
       "2  How can I increase the speed of my internet co...         18          9\n",
       "3  Why am I mentally very lonely? How can I solve...         13          0\n",
       "4  Which one dissolve in water quikly sugar, salt...          1          0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_topic_results = nmf_model.transform(dtm_tf)\n",
    "LDA_topic_results = LDA_model.transform(dtm_tf)\n",
    "\n",
    "df['NMF_Topic'] = nmf_topic_results.argmax(axis=1)\n",
    "df['LDA_Topic'] = LDA_topic_results.argmax(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    43485\n",
       "0     34101\n",
       "11    33025\n",
       "1     29967\n",
       "12    26315\n",
       "5     24029\n",
       "18    22262\n",
       "8     20395\n",
       "16    19562\n",
       "13    17420\n",
       "9     16968\n",
       "3     16646\n",
       "2     15322\n",
       "6     14542\n",
       "10    13315\n",
       "15    13108\n",
       "17    12226\n",
       "4     11448\n",
       "7     10301\n",
       "14     9852\n",
       "Name: NMF_Topic, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NMF_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
